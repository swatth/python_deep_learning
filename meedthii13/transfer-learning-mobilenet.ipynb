{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer-learning-mobilenet.ipynb","provenance":[{"file_id":"1mGY-wLxo0ZRXf1pba3NNwu1rPkYFAC75","timestamp":1587925324906}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XnNnl5lsIWb-","colab_type":"code","colab":{}},"source":["#hyper parameters used \n","\n","lr_init = 0.001\n","lr_fine_tuned = 0.00001\n","batch_sz = 64\n","dropout_rate = 0.3\n","image_size = 224"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"enCERURLvbR3","colab_type":"code","colab":{}},"source":["import os\n","import random\n","import shutil\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.applications import MobileNet \n","from tensorflow.keras.applications.mobilenet import preprocess_input\n","\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.models import Model,load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import backend as K\n","\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpqNnqgeVsc0","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8biolpAW1lK","colab_type":"code","colab":{}},"source":["#this assumes the zip file exists on the root location of the Google Drive\n","#the name \"small.zip\" indicates the images have been resized to for mobilenet model\n","!unzip -q \"drive/My Drive/small.zip\" "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ck4SvE5R-Xoh","colab_type":"code","colab":{}},"source":["def split_tr_tst(src_dir, tr_dir, tst_dir,tr_split = 0.8):\n","    items = os.listdir(src_dir)\n","    #print(items[1])\n","    random.shuffle(items)\n","    tst_cnt = round(len(items) * (1-tr_split))\n","    #print(tst_cnt)\n","    #print(items[1])\n","    test_items = items[:tst_cnt]\n","    train_items = items[tst_cnt:]\n","    if not(os.path.exists(tst_dir)):\n","                print('creating ', tst_dir)\n","                os.makedirs(tst_dir)\n","    for item in test_items:\n","        item_path = os.path.join(src_dir,item)\n","        dest_path = os.path.join(tst_dir, item)\n","        shutil.copyfile(item_path,dest_path)\n","    if not(os.path.exists(tr_dir)):\n","                print('creating ', tr_dir)\n","                os.makedirs(tr_dir)\n","    for item in train_items:\n","        item_path = os.path.join(src_dir,item)\n","        dest_path = os.path.join(tr_dir, item)\n","        shutil.copyfile(item_path,dest_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EfOA2Aex-gvh","colab_type":"code","colab":{}},"source":["#indicate the directory name for the source \n","#(source is \"./small\" if extracted from the default zip file and run by the code above)\n","#we'll need traning set and testing set\n","\n","base_path = '.'\n","src = 'small'\n","tr = 'train'\n","tst = 'test'\n","\n","dir_list = os.listdir(os.path.join(base_path,src))\n","\n","#count the directories inside train dir for the number of category\n","#will be used to determine the number of classes of the model\n","num_categories = len(dir_list)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOsL4GlRGQuo","colab_type":"code","colab":{}},"source":["#only run this if there's still no data split between train and test set\n","for item in dir_list:\n","  src_dir = os.path.join(base_path,src,item)\n","  tr_dir = os.path.join(base_path,tr,item)\n","  tst_dir = os.path.join(base_path,tst,item)\n","  \n","  split_tr_tst(src_dir, tr_dir, tst_dir,tr_split = 0.75)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRwq5vAhFWui","colab_type":"code","colab":{}},"source":["train_dir = os.path.join(base_path,tr)\n","test_dir = os.path.join(base_path,tst)\n","\n","# Add our data-augmentation parameters to ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,\n","    zoom_range=0.3,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    preprocessing_function=preprocess_input)\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input)\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir, # This is the source directory for training images\n","        target_size=(image_size, image_size),  \n","        batch_size=batch_sz,\n","        class_mode='categorical')\n","\n","#get dictionary for the label name from the train_generator\n","class_dict = train_generator.class_indices.items()\n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(image_size, image_size),\n","        batch_size=batch_sz,\n","        class_mode='categorical')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGFBqJoTUuyQ","colab_type":"code","colab":{}},"source":["x_batch, y_batch = next(train_generator)\n","print(x_batch.shape)\n","\n","fig = plt.figure(figsize=(8,8))\n","\n","#show only the first 64 samples if batch size is over 64\n","for i in range(min(batch_sz,64)):\n","  fig.add_subplot(8, 8, 1 + i, xticks=[], yticks=[])\n","\n","  #mobileNet preprocessing convert color range to [-1,1]\n","  #need to change to [0,1] to show color properly\n","  plt.imshow((x_batch[i]+1)/2)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIGF5G0l2R3t","colab_type":"code","colab":{}},"source":["x_batch, y_batch = next(test_generator)\n","\n","print(x_batch.shape)\n","\n","fig = plt.figure(figsize=(8,8))\n","\n","#show only the first 64 samples if batch size is over 64\n","for i in range(min(batch_sz,64)):\n","  fig.add_subplot(8, 8, 1 + i, xticks=[], yticks=[])\n","  #mobileNet preprocessing convert color range to [-1,1]\n","  #need to change to [0,1] to show color properly\n","  plt.imshow((x_batch[i]+1)/2)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VFgWZpfwqhX","colab_type":"code","colab":{}},"source":["pretrained_model =  MobileNet(input_shape=(image_size,image_size,3), include_top=False)\n","\n","#freeze all layers\n","for layer in pretrained_model.layers:\n","  layer.trainable = False\n","  \n","pretrained_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOlk6yumzK4K","colab_type":"code","colab":{}},"source":["def build_model(base_model, num_categories):\n","\n","  #get the original output (before its actual top layer) from MobileNet\n","  org_output = base_model.layers[-1].output\n","\n","  #the other form for building model in functional style\n","  #since we cant use the other method to modify pre-built models\n","\n","  #x represent the output of the model we're modifying\n","  x = GlobalAveragePooling2D()(org_output)\n","  x = Dense(1024, activation='relu', name='custom_dense1024')(x)\n","  x = Dropout(dropout_rate)(x)\n","  x = Dense(num_categories, activation='softmax', name='output')(x)\n","\n","  #create a new model from the existing pre-trained model stacking with our layers\n","  return Model(base_model.input, x)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7rEHbooNQl-","colab_type":"code","colab":{}},"source":["model = build_model(pretrained_model, num_categories)\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozkWf1wy6VYw","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy', \n","              optimizer=Adam(lr=lr_init), \n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XPrR3xZIKYwl","colab":{}},"source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=32,\n","      epochs=5,\n","      validation_data=test_generator,\n","      validation_steps=10,\n","      verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9EkImxuQiWS","colab_type":"code","colab":{}},"source":["#save weights and rebuilt the model\n","#the reason we do this is because we need to re-compile the model\n","#if we want to change the learning rate\n","#and it causes out-of-memery error \n","#if we do that too many times\n","\n","model.save_weights('model_weights.h5')\n","\n","#rebuild and re-load weights\"\n","model = build_model(pretrained_model, num_categories)\n","model.load_weights('model_weights.h5')\n","\n","\n","#unfreeze the layers down to conv_pw_9\n","\n","reached_conv_pw_9 = False\n","for layer in model.layers:\n","    if layer.name == 'conv_pw_9':\n","        reached_conv_pw_9 = True\n","    if reached_conv_pw_9:\n","        layer.trainable = True\n","        \n","model.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv5MN61oSRKq","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy', \n","              optimizer=Adam(lr=lr_fine_tuned), \n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFvaPnAbSsdR","colab_type":"code","colab":{}},"source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=32,\n","      epochs=20,\n","      validation_data=test_generator,\n","      validation_steps=10,\n","      verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-DUfY_y4TrH","colab_type":"code","colab":{}},"source":["img_path = 'knife-vol5.png'\n","img = image.load_img(img_path, target_size=(image_size,image_size))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis = 0)\n","x = preprocess_input(x)\n","\n","print(model.predict(x))\n","print(class_dict)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tBwXvypj2wDV","colab_type":"code","colab":{}},"source":["model.save('drive/My Drive/meedthii13_ver2.hdf5')"],"execution_count":0,"outputs":[]}]}